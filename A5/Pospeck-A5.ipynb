{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A5- Reinforcement Learning Solution to the Towers of Hanoi Puzzle\n",
    "Bradley Pospeck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, reinforcement learning will be used to solve the [Towers of Hanoi](https://en.wikipedia.org/wiki/Tower_of_Hanoi).  \n",
    "\n",
    "To keep things simpler, I will be writing code to handle just a 3 peg, 3 disc tower of hanoi. I can always come back in the future and generalize it to any amount of discs and pegs. The machine learning algorithm will allow the program to teach itself how to solve the Towers of Hanoi optimally.\n",
    "\n",
    "The reinforcement learning technique used will be based on state-action value, or Q, functions. The Q function will keep track of learned outcomes of each individual state-action pair and update itself constantly as it learns what is best. The updates to the Q function will be done with temporal difference (TD). TD uses $\\text{value}(s_{t+1},a_{t+1})$ as an estimate of return from the next state to update the current state-action value: $\\;\\;\\; \\text{value}(s_t,a_t) \\approx r_{t+1} + \\text{value}(s_{t+1},a_{t+1})$\n",
    "\n",
    "States and actions can be various things, depending on the problem. In the case of the Towers of Hanoi, the state represents which discs are on which pegs and in what order. The actions represent the valid set of discs that can be moved to a different peg legally. For example: the image below, from http://www.texample.net/media/tikz/examples/PNG/towers-of-hanoi.png, represents the starting state of a typical 3 disc, 3 peg Tower of Hanoi. In this case, there are 2 valid moves (or actions) that can be taken. Disc 1 can be moved from the 1st peg to either the 2nd or 3rd peg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.texample.net/media/tikz/examples/PNG/towers-of-hanoi.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://www.texample.net/media/tikz/examples/PNG/towers-of-hanoi.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Towers of Hanoi Setup Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For purposes of debugging, and being able to see the path the program takes, it makes sense to start with a function that can print the state of the Tower of Hanoi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printState(copyState):\n",
    "    \"\"\"state is a list of lists. Each inner list represents a peg and contains the discs. Smaller discs are smaller numbers\"\"\"\n",
    "    discCount = [0]*3    # will store the number of discs on each peg\n",
    "    index = 0\n",
    "    state = copy.deepcopy(copyState)\n",
    "    for peg in state:\n",
    "        if not peg: \n",
    "            index += 1\n",
    "            continue\n",
    "        discCount[index] = len(peg)\n",
    "        index += 1\n",
    "    maxDisc = max(discCount)\n",
    "    while maxDisc > 0:\n",
    "        if not state[0] or len(state[0]) != maxDisc:\n",
    "            print(\" \",end='')\n",
    "        else:\n",
    "            print(state[0][0],end='')\n",
    "            state[0].pop(0)\n",
    "        if not state[1] or len(state[1]) != maxDisc:\n",
    "            print(\" \",end='')\n",
    "        else:\n",
    "            print(state[1][0],end='')\n",
    "            state[1].pop(0)\n",
    "        if not state[2] or len(state[2]) != maxDisc:\n",
    "            print(\" \")\n",
    "        else:\n",
    "            print(state[2][0])\n",
    "            state[2].pop(0)\n",
    "        maxDisc -= 1\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need to be able to tell the program which moves are valid at any given state so that it understands the action rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validMoves(state):\n",
    "    \"\"\"Returns a list of valid moves from state\"\"\"\n",
    "    topDisc = [4]*3; # 4 means no disc is on that peg, makes logic simpler in 2d for loop below\n",
    "    for i in range(3):\n",
    "        if not state[i]:\n",
    "            continue\n",
    "        else:\n",
    "            topDisc[i] = state[i][0]\n",
    "    moves = []\n",
    "    for i in range(3): # always 3 pegs\n",
    "        for j in range(i+1,3):\n",
    "            if topDisc[i] < topDisc[j]:\n",
    "                moves.append([i+1,j+1])\n",
    "            elif topDisc[i] > topDisc[j]:\n",
    "                moves.append([j+1,i+1])\n",
    "    return moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next it is important to be able to take an action, or move, from a given state and know what that resultant state is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeMove(state, move):\n",
    "    \"Returns a new copy of the state after applying the move\"\n",
    "    newState = copy.deepcopy(state)\n",
    "    fromPeg, toPeg = move # move is 1-based indexing, need to convert to 0 based indexing\n",
    "    fromPeg -= 1\n",
    "    toPeg   -= 1\n",
    "    disc = newState[fromPeg].pop(0)\n",
    "    newState[toPeg].insert(0, disc)\n",
    "    return newState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple function that converts a state-move pair into one large tuple. Since Q in the next section is defined as a dictionary, we need to use immutable objects as the keys. Without this function, states and moves are just represented as lists. This function allows easy repeated conversion for the Q dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stateMoveTuple(state, move):\n",
    "    \"\"\"Returns a tuple of state and move\"\"\"\n",
    "    return ((tuple(state[0]),tuple(state[1]),tuple(state[2])), (tuple(move)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The move policy employed will be an epsilon greedy policy. Typically `epsilon` starts at 1.0 and slowly degrades to 0.0 over many iterations. The larger `epsilon` is, the more likely it is that the policy will choose a random, valid move to take. The smaller `epsilon` is, the more likely it is that the policy will choose the best greedy, valid move that it knows. Initially, it will be taking many random moves in order to explore as much of the state space as it can. As it learns more, it will slowly start to take what it believes to be the best actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def epsilonGreedy(epsilon, Q, state, validMovesF):\n",
    "    validMoves = validMovesF(state)\n",
    "    if np.random.uniform() < epsilon:\n",
    "        # Random Move\n",
    "        return random.choice(validMoves)\n",
    "    else:\n",
    "        # Greedy Move\n",
    "        Qs = np.array([Q.get(stateMoveTuple(state,m), 0) for m in validMoves]) \n",
    "        return validMoves[ np.argmax(Qs) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training $Q$, several key parameters are involved: `learningRate`, `epsilon`, and `epsilonDecayFactor`. As discussed above, `epsilon` starts at 1 and slowly decays to 0 and controls the random factor of making a valid move. The `epsilonDecayFactor` is as it sounds: It's the number that decays epsilon from 1 to 0. The faster `epsilon` decays, the less it will learn about the entire state space. This means it may not learn enough to solve the Towers of Hanoi in the smallest number of moves. Therefore, it is important to have `epsilon` decay at a slow enough rate to produce a reliable $Q$.\n",
    "\n",
    "The `learningRate` ,$\\rho$, controls how much $Q$ is updated by when using TD update. When this parameter is high, updates to $Q$ are more aggressive and it quickly changes the state-move pair values. This can run faster, but also has the potential to overshoot the \"correct\" state-move pair values. So even though a smaller `learningRate` means slower learning, it generally means more accurate approximations than with a larger `learningRate`.\n",
    "\n",
    "The reinforcement value, $r$, being used is -1. This represents moving one disc to another peg. Since we want to minimize the number of moves, and the reinforcement is negative, we will actually want to maximize our reinforcements. The reinforcement to update $Q$ will be that initial value of -1 added to the difference between the current state-move value and the previous state-move value. That's what this Temporal Difference error is: \n",
    "\n",
    "$\\;\\;\\; \\text{value}(s_t,a_t) \\approx r_{t+1} + \\text{value}(s_{t+1},a_{t+1})$\n",
    "\n",
    "This value will be multiplied to the `learningRate` mentioned above and finally added to the current $Q$ estimation of that previous state-move value. This yields our final $Q$ update to be the following:\n",
    "\n",
    "$$\n",
    "    \\begin{align*}\n",
    "      Q(s_t,a_t) = Q(s_t,a_t) + \\rho (r_{t+1} + Q(s_{t+1},a_{t+1}) - Q(s_t,a_t))\n",
    "    \\end{align*}\n",
    "$$\n",
    "\n",
    "where s/t subscripts represent the old state/move and s+1/t+1 subscripts represent the current state/move. When the goal is reached, $r = -1$, since that is the true length of the path from the previous state to the current goal state.\n",
    "\n",
    "The function `trainQ` below handles all of that, using `epsilonGreedy` above to choose a move. It also keeps track of the number of steps it took to solve the tower of hanoi in each repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainQ(nRepetitions, learningRate, epsilonDecayFactor, validMovesF, makeMoveF):\n",
    "    \"\"\"Train Q fcn for number of repetitions, decaying epsilon at start of each repetition. \n",
    "        Returns Q and list of number of steps to reach goal for each repetition\"\"\"\n",
    "    epsilon = 1.0\n",
    "    stepsToGoal = np.zeros(nRepetitions)\n",
    "    Q = {}\n",
    "    for rep in range(nRepetitions):\n",
    "        epsilon *= epsilonDecayFactor\n",
    "        step = 0\n",
    "        state = [[1,2,3],[],[]]  # Start state for 3-dic, 3-peg Towers of Hanoi hardcoded\n",
    "        done = False\n",
    "        while not done:        \n",
    "            step += 1\n",
    "            move = epsilonGreedy(epsilon, Q, state, validMovesF)\n",
    "            stateNew = copy.deepcopy(state)\n",
    "            stateNew = makeMoveF(stateNew,move)\n",
    "            if (stateMoveTuple(state,move)) not in Q:\n",
    "                Q[stateMoveTuple(state,move)] = -1  # initial Q value for new state,move pair         \n",
    "            if stateNew == [[],[],[1,2,3]]:\n",
    "                # Towers of Hanoi completed\n",
    "                Q[stateMoveTuple(state,move)] = -1\n",
    "                done = True\n",
    "                stepsToGoal[rep] = step              \n",
    "            if step > 1:\n",
    "                # Update Q\n",
    "                Q[stateMoveTuple(stateOld,moveOld)] += learningRate * (-1 + Q[stateMoveTuple(state,move)] - Q[stateMoveTuple(stateOld,moveOld)])           \n",
    "            stateOld, moveOld = state, move # remember state and move to Q(state,move)\n",
    "            state = stateNew\n",
    "    return Q, stepsToGoal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the final function, `testQ`. It will use the trained $Q$ function from `trainQ` and see how well it solves one instance of the 3-disc, 3-peg Tower of Hanoi puzzle. `epsilonGreedy` is also used here, but to ensure it does not pick a random move, it is given $\\epsilon = 0$. If the solution is found within `maxSteps`, the path to get there will be returned in a list. If the solution was not found within those steps, it will return a list containing a string saying it did not find a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testQ(Q, maxSteps, validMovesF, makeMoveF):\n",
    "    \"\"\"Without updating Q, use Q to find greedy action each step until goal is found. Returns path of states\"\"\"\n",
    "    state = [[1,2,3],[],[]]\n",
    "    path = [state]\n",
    "    for step in range(maxSteps):\n",
    "        move = epsilonGreedy(0, Q, state, validMovesF)\n",
    "        state = makeMove(state,move)\n",
    "        path.append(state)\n",
    "        if state == [[],[],[1,2,3]]:\n",
    "            # Towers of Hanoi finished return path\n",
    "            return path\n",
    "    # Didn't finish towers of hanoi\n",
    "    return ['Did not find solution in {} steps'.format(maxSteps)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, just some basic testing of the Towers of Hanoi functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \n",
      "2  \n",
      "3  \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "state = [[1, 2, 3], [], []]\n",
    "printState(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, I found that my `printState` was destroying the state passed into it. I was performing a shallow copy of state inside the function, but because it's a list of lists that was not sufficient. After changing the copy to a deepcopy, it did not destroy the original state that was passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((1, 2, 3), (), ()), (1, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move =[1, 2]\n",
    "stateMoveTuple(state, move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3], [1], []]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newstate = makeMove(state, move)\n",
    "newstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  \n",
      "31 \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "printState(newstate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the fun testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q, stepsToGoal = trainQ(50, 0.5, 0.7, validMoves, makeMove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It could be interesting to see what the estimates are of each state-move pair. The max size of the $Q$ dictionary is 76. Might as well take a peek to see if it explored every possible state-move pair at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({(((), (1,), (2, 3)), (2, 1)): -1.5,\n",
       "  (((), (1,), (2, 3)), (2, 3)): -1,\n",
       "  (((), (1,), (2, 3)), (3, 1)): -1.75,\n",
       "  (((), (1, 2), (3,)), (2, 1)): -3.000000000031534,\n",
       "  (((), (1, 2), (3,)), (2, 3)): -3.7783203125,\n",
       "  (((), (1, 2), (3,)), (3, 1)): -3.66796875,\n",
       "  (((), (1, 2, 3), ()), (2, 1)): -5.1181640625,\n",
       "  (((), (1, 2, 3), ()), (2, 3)): -4.5703125,\n",
       "  (((), (1, 3), (2,)), (2, 1)): -5.064453125,\n",
       "  (((), (1, 3), (2,)), (2, 3)): -5.2044677734375,\n",
       "  (((), (1, 3), (2,)), (3, 1)): -4.716796875,\n",
       "  (((), (2,), (1, 3)), (2, 1)): -3.3125,\n",
       "  (((), (2,), (1, 3)), (3, 1)): -3.05078125,\n",
       "  (((), (2,), (1, 3)), (3, 2)): -3.078125,\n",
       "  (((), (2, 3), (1,)), (2, 1)): -4.41796875,\n",
       "  (((), (2, 3), (1,)), (3, 1)): -5.033203125,\n",
       "  (((), (2, 3), (1,)), (3, 2)): -4.46875,\n",
       "  (((), (3,), (1, 2)), (2, 1)): -5.497283935546875,\n",
       "  (((), (3,), (1, 2)), (3, 1)): -5.2435302734375,\n",
       "  (((), (3,), (1, 2)), (3, 2)): -5.0966796875,\n",
       "  (((1,), (), (2, 3)), (1, 2)): -1.75,\n",
       "  (((1,), (), (2, 3)), (1, 3)): -1,\n",
       "  (((1,), (), (2, 3)), (3, 2)): -2.375,\n",
       "  (((1,), (2,), (3,)), (1, 2)): -3.626953125,\n",
       "  (((1,), (2,), (3,)), (1, 3)): -2.59375,\n",
       "  (((1,), (2,), (3,)), (2, 3)): -2.000000000000739,\n",
       "  (((1,), (2, 3), ()), (1, 2)): -5.1025390625,\n",
       "  (((1,), (2, 3), ()), (1, 3)): -4.935546875,\n",
       "  (((1,), (2, 3), ()), (2, 3)): -5.3134765625,\n",
       "  (((1,), (3,), (2,)), (1, 2)): -5.1962890625,\n",
       "  (((1,), (3,), (2,)), (1, 3)): -5.02294921875,\n",
       "  (((1,), (3,), (2,)), (3, 2)): -5.0849609375,\n",
       "  (((1, 2), (), (3,)), (1, 2)): -2.9638671875,\n",
       "  (((1, 2), (), (3,)), (1, 3)): -3.0859375,\n",
       "  (((1, 2), (), (3,)), (3, 2)): -3.34375,\n",
       "  (((1, 2), (3,), ()), (1, 2)): -4.083984375,\n",
       "  (((1, 2), (3,), ()), (1, 3)): -3.734375,\n",
       "  (((1, 2), (3,), ()), (2, 3)): -3.8203125,\n",
       "  (((1, 2, 3), (), ()), (1, 2)): -7.219295501708984,\n",
       "  (((1, 2, 3), (), ()), (1, 3)): -7.000000611315893,\n",
       "  (((1, 3), (), (2,)), (1, 2)): -6.173255920410156,\n",
       "  (((1, 3), (), (2,)), (1, 3)): -5.59564208984375,\n",
       "  (((1, 3), (), (2,)), (3, 2)): -5.65032958984375,\n",
       "  (((1, 3), (2,), ()), (1, 2)): -5.1092987060546875,\n",
       "  (((1, 3), (2,), ()), (1, 3)): -5.68109130859375,\n",
       "  (((1, 3), (2,), ()), (2, 3)): -5.52532958984375,\n",
       "  (((2,), (), (1, 3)), (1, 2)): -2.921875,\n",
       "  (((2,), (), (1, 3)), (3, 1)): -3.0625,\n",
       "  (((2,), (), (1, 3)), (3, 2)): -2.796875,\n",
       "  (((2,), (1,), (3,)), (1, 3)): -1.9990234375,\n",
       "  (((2,), (1,), (3,)), (2, 1)): -2.125,\n",
       "  (((2,), (1,), (3,)), (2, 3)): -2.125,\n",
       "  (((2,), (1, 3), ()), (1, 3)): -4.234375,\n",
       "  (((2,), (1, 3), ()), (2, 1)): -4.4228515625,\n",
       "  (((2,), (1, 3), ()), (2, 3)): -4.435546875,\n",
       "  (((2,), (3,), (1,)), (1, 2)): -4.16796875,\n",
       "  (((2,), (3,), (1,)), (3, 1)): -4.189453125,\n",
       "  (((2,), (3,), (1,)), (3, 2)): -4.5107421875,\n",
       "  (((2, 3), (), (1,)), (1, 2)): -6.000000082525461,\n",
       "  (((2, 3), (), (1,)), (3, 1)): -6.20098876953125,\n",
       "  (((2, 3), (), (1,)), (3, 2)): -6.524391174316406,\n",
       "  (((2, 3), (1,), ()), (1, 3)): -6.494441986083984,\n",
       "  (((2, 3), (1,), ()), (2, 1)): -7.2500797510147095,\n",
       "  (((2, 3), (1,), ()), (2, 3)): -6.4593048095703125,\n",
       "  (((3,), (), (1, 2)), (1, 2)): -5.59698486328125,\n",
       "  (((3,), (), (1, 2)), (3, 1)): -5.866729736328125,\n",
       "  (((3,), (), (1, 2)), (3, 2)): -5.411651611328125,\n",
       "  (((3,), (1,), (2,)), (2, 1)): -6.09814453125,\n",
       "  (((3,), (1,), (2,)), (2, 3)): -6.115760803222656,\n",
       "  (((3,), (1,), (2,)), (3, 1)): -5.9240875244140625,\n",
       "  (((3,), (1, 2), ()), (1, 3)): -4.000000000649129,\n",
       "  (((3,), (1, 2), ()), (2, 1)): -4.796875,\n",
       "  (((3,), (1, 2), ()), (2, 3)): -4.699951171875,\n",
       "  (((3,), (2,), (1,)), (2, 1)): -5.608917236328125,\n",
       "  (((3,), (2,), (1,)), (3, 1)): -5.6507568359375,\n",
       "  (((3,), (2,), (1,)), (3, 2)): -5.000000008600969},\n",
       " 76)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q, len(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After multiple tests, the results are fairly consistent. The majority of the time, it has explored every possible state space at least once.\n",
    "\n",
    "Let's plot the number of moves it took to solve the Tower of Hanoi in each of its attempts. The number of iterations had to be kept fairly low in order to see the graph well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1b92ec7be10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b92ec544a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stepsToGoal);\n",
    "plt.xlabel('Towers of Hanoi Iteration #')\n",
    "plt.ylabel('Number of steps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, after several tries of running `trainQ`, the results are fairly consistent. There's always up and down spikes in roughly the 1st half of the 50 iterations. After that, $Q$ reliably solves the Tower of Hanoi in a perfect 7 steps every time.\n",
    "\n",
    "Below is the last test: `testQ`. Given that the graph above seems to have the solution down perfectly, it's reasonable to expect `testQ` will return the perfect path to the 3-disc, 3-peg version of Towers of Hanoi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = testQ(Q, 20, validMoves, makeMove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  \n",
      "2  \n",
      "3  \n",
      "---\n",
      "\n",
      "2  \n",
      "3 1\n",
      "---\n",
      "\n",
      "321\n",
      "---\n",
      "\n",
      " 1 \n",
      "32 \n",
      "---\n",
      "\n",
      " 1 \n",
      " 23\n",
      "---\n",
      "\n",
      "123\n",
      "---\n",
      "\n",
      "  2\n",
      "1 3\n",
      "---\n",
      "\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in path:\n",
    "    printState(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing validMoves([[1], [2], [3]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[1, 2], [1, 3], [2, 3]]\n",
      "\n",
      "Testing validMoves([[], [], [1, 2, 3]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[3, 1], [3, 2]]\n",
      "\n",
      "Testing makeMove([[], [], [1, 2, 3]], [3, 2])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[], [1], [2, 3]]\n",
      "\n",
      "Testing makeMove([[2], [3], [1]], [1, 2])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[], [2, 3], [1]]\n",
      "\n",
      "Testing   Q, steps = trainQ(1000, 0.5, 0.7, validMoves, makeMove).\n",
      "\n",
      "--- 10/10 points. Q dictionary has correct number of entries.\n",
      "\n",
      "--- 10/10 points. The mean of the number of steps is 7.433 which is correct.\n",
      "\n",
      "Testing   path = testQ(Q, 20, validMoves, makeMove).\n",
      "\n",
      "--- 20/20 points. Correctly returns path of length 8, less than 10.\n",
      "\n",
      "C:\\Users\\Bradley\\Desktop\\Classes\\cs440\\A5 Execution Grade is 80/80\n",
      "\n",
      " Remaining 20 points will be based on your text describing the trainQ and test! functions.\n",
      "\n",
      "C:\\Users\\Bradley\\Desktop\\Classes\\cs440\\A5 FINAL GRADE is __/100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b92ec13160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i A5grader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
